{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e410db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response=requests.get('http://ihgfspringfair.epch.in/springfair/exhibitor-list/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61428aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: ANTIQUE INDIA FURNITURE\n",
      "Email: mailto:info@antiqueindiafurniture.com\n",
      "Web address: http://www.antiqueindiafurniture.com\n",
      "Company Location: ANTIQUE INDIA FURNITURE  148, 3RD PHASE, ROOP RAJAT TOWNSHIP, OPP BHADU MARKET, PAL ROAD, JODHPUR RAJASTHAN, 342001\n",
      "Contact Person: MS. SHASHI BHATI\n",
      "Contact Person Mobile Number: 91-9828724349\n",
      "Contact Person Phone Number: 91-291-2970687, 2970689\n",
      "Product Categories: FURNITURE, FURNITURE HARDWARE & ACCESSORIES INCLUDING CANE, BAMBOO, NATURAL FIBER & ECO FRIENDLY PRODUCTS\n"
     ]
    }
   ],
   "source": [
    "# soup=BeautifulSoup(response.content,'html.parser')\n",
    "\"\"\"Company name\n",
    "Email\n",
    "Web address\n",
    "Company location\n",
    "Contact person\n",
    "Contact person mobile number\n",
    "Contact person phone number\n",
    "Product categories\n",
    "\"\"\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response=requests.get('http://ihgfspringfair.epch.in/springfair/author/29791/')\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "table_rows = soup.find('table', class_='tabl').find_all('tr')\n",
    "\n",
    "# Initialize variables to store values\n",
    "data = {}\n",
    "\n",
    "# Iterate through the rows and extract the required information\n",
    "for row in table_rows:\n",
    "    row_data = row.find_all('td')\n",
    "    if len(row_data) >= 2:\n",
    "        header = row_data[0].find('b')\n",
    "        if header:\n",
    "            header_text = header.text.strip()\n",
    "            if header_text == \"Company Name\":\n",
    "                data['Company Name'] = row_data[1].find('span').text.strip()\n",
    "            elif header_text == \"Email\":\n",
    "                data['Email'] = row_data[1].find('a')['href']\n",
    "            elif header_text == \"Web address\":\n",
    "                data['Web address'] = row_data[1].find('a').text.strip()\n",
    "            elif header_text == \"Company Location\":\n",
    "                data['Company Location'] = row_data[1].text.strip()\n",
    "            elif header_text == \"Contact Person\":\n",
    "                data['Contact Person'] = row_data[1].text.strip()\n",
    "            elif header_text == \"Contact Person Mobile Number\":\n",
    "                data['Contact Person Mobile Number'] = row_data[1].text.strip()\n",
    "            elif header_text == \"Contact Person Phone Number\":\n",
    "                data['Contact Person Phone Number'] = row_data[1].text.strip()\n",
    "            elif header_text == \"Product Categories\":\n",
    "                data['Product Categories'] = row_data[1].text.strip()\n",
    "\n",
    "# Print the extracted values\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49eae8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid URL: tablescraper-selected-row href\n",
      "Extraction and saving complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xlwt\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to extract data from a URL\n",
    "def extract_data_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    table_rows = soup.find('table', class_='tabl').find_all('tr')\n",
    "    try:\n",
    "        for row in table_rows:\n",
    "            row_data = row.find_all('td')\n",
    "            if len(row_data) >= 2:\n",
    "                header = row_data[0].find('b')\n",
    "                if header:\n",
    "                    header_text = header.text.strip()\n",
    "                    if header_text == \"Company Name\":\n",
    "                        data['Company Name'] = row_data[1].find('span').text.strip()\n",
    "                    elif header_text == \"Email\":\n",
    "                        data['Email'] = row_data[1].find('a')['href']\n",
    "                    elif header_text == \"Web address\":\n",
    "                        data['Web address'] = row_data[1].find('a').text.strip()\n",
    "                    elif header_text == \"Company Location\":\n",
    "                        data['Company Location'] = row_data[1].text.strip()\n",
    "                    elif header_text == \"Contact Person\":\n",
    "                        data['Contact Person'] = row_data[1].text.strip()\n",
    "                    elif header_text == \"Contact Person Mobile Number\":\n",
    "                        data['Contact Person Mobile Number'] = row_data[1].text.strip()\n",
    "                    elif header_text == \"Contact Person Phone Number\":\n",
    "                        data['Contact Person Phone Number'] = row_data[1].text.strip()\n",
    "                    elif header_text == \"Product Categories\":\n",
    "                        data['Product Categories'] = row_data[1].text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return data\n",
    "\n",
    "# Read URLs from Excel file using pandas\n",
    "input_excel = 'exhibition_links.xls'\n",
    "output_excel = 'output_data_exhibition.xls'\n",
    "\n",
    "urls_df = pd.read_excel(input_excel)\n",
    "urls = urls_df['URL']\n",
    "\n",
    "# Create a new Excel workbook\n",
    "output_workbook = xlwt.Workbook()\n",
    "output_sheet = output_workbook.add_sheet('Data')\n",
    "\n",
    "# Write headers to the output sheet\n",
    "headers = ['Company Name', 'Email', 'Web address', 'Company Location', \n",
    "           'Contact Person', 'Contact Person Mobile Number', 'Contact Person Phone Number', \n",
    "           'Product Categories']\n",
    "for col, header in enumerate(headers):\n",
    "    output_sheet.write(0, col, header)\n",
    "\n",
    "\n",
    "# Iterate through the URLs, extract data, and write to the output sheet\n",
    "for row, url in enumerate(urls, start=1):\n",
    "    if url.startswith('http://') or url.startswith('https://'):\n",
    "        try:\n",
    "            extracted_data = extract_data_from_url(url)\n",
    "            for col, header in enumerate(headers):\n",
    "                output_sheet.write(row, col, extracted_data.get(header, ''))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Save the output workbook after each iteration\n",
    "        output_workbook.save(output_excel)\n",
    "    else:\n",
    "        print(f\"Skipping invalid URL: {url}\")\n",
    "\n",
    "print(\"Extraction and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0531985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
